---
title: "Marketing Campaign Response Prediction"
lang: en
subtitle: "Using Gradient Boosted Trees"
author: Jan Kirenz
execute:
  eval: true
  echo: true
highlight-style: github
format:
  revealjs: 
    toc: true
    toc-depth: 1
    embed-resources: false
    output-location: fragment
    theme: [dark, ../custom.scss]  
    incremental: true
    transition: slide
    transition-speed: slow
    background-transition: fade
    code-copy: true
    code-line-numbers: true
    smaller: false
    scrollable: true
    slide-number: c
    preview-links: auto
    chalkboard: 
      buttons: false
    #logo: images/logo.png
    footer: Jan Kirenz
jupyter: python3   
---


```{python}
# | echo: false

import requests
import numpy as np
import altair as alt
import pandas as pd
from joblib import dump, load

from sklearn.ensemble import GradientBoostingClassifier

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

```


# Introduction

![](images/marketing-campaign.png)

- Predict the response to a marketing campaign


## Example Payback

![](images/payback.jpeg)

## Marketing use case

- The goal is to predict if 
   - a customer 
   - will respond positively (e.g. buys a product)
   - to a future campaign 
   - based on their features

- We use data from previous campaigns to train a model


# Data

## Data overview

- `age`: Customer's age (integer)
- `city`: Customer's place of residence (string: 'Berlin', 'Stuttgart')
- `income`: Customer's annual income (integer)
- `membership_days`: Number of days the customer has been a member (integer)
- `campaign_engagement`: Number of times the customer engaged with previous campaigns (integer)
- `target`: Whether the customer responded positively to the campaign (0 or 1)

## Import data

```{python}
df = pd.read_csv(
    'https://raw.githubusercontent.com/kirenz/datasets/master/campaign.csv')
```

## Data overview

```{python}
df
```

## Data info

```{python}
df.info()
```

## Data corrections

- Encode categorical variables 

. . .

```{python}
df = pd.get_dummies(df, columns=['city'])
```

. . .

```{python}
df.info()

```

## Data splitting

- Split the df into features (X) and target (y)

. . .

```{python}
X = df.drop('target', axis=1)
y = df['target']
```

- Save feature names for later evaluation steps

. . .

```{python}
feature_names = X.columns
```

- Make train and test split

. . .

```{python}
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)
```


# Model

## Select model

- Define hyperparameters as dictionary

. . .

```{python}
# | code-line-numbers: "|1|2|3|4"

params = {
    "n_estimators": 50,
    "max_depth": 3,
    "min_samples_split": 5,
}
```

- `n_estimators`: Number of gradient boosted trees
- `max_depth`: Maximum tree depth
- `min_samples_split`: The minimum number of samples required to split an internal node

. . .

```{python}
clf = GradientBoostingClassifier(**params)
```

## Train model

- Train the model on the *training* data

. . .

```{python}
clf.fit(X_train, y_train)
```

## Evaluate model

- Predict on the *testing* data

. . .

```{python}
# Predict on the testing data
y_pred = clf.predict(X_test)

```

- Calculate accuracy

. . .

```{python}
accuracy_score(y_test, y_pred)
```

## Confusion matrix

- Print confusion matrix 

. . .

```{python}
print(confusion_matrix(y_test, y_pred))

```


## Classification report

- Print classification report

. . .
 
```{python}
print(classification_report(y_test, y_pred))

```

## Obtain feature importance

- Obtain feature importance

. . .

```{python}
feature_importance = clf.feature_importances_
```

- Save as dataframe

. . .

```{python}
df_features = pd.DataFrame(
    {"score": feature_importance,
     "name": feature_names})

df_features

```

## Plot feature importance

```{python}
alt.Chart(df_features).mark_bar().encode(
    x=alt.X('score'),
    y=alt.Y('name', sort='-x')
).properties(
    width=800,
    height=300
)

```


## Save model

```{python}
# | eval: false

model_filename = 'gradientboosted_model.joblib'
dump(clf, model_filename)
```


# Next steps? 

## Status quo

1. We trained a model

2. Our model makes a prediction if a customer will respond positively or not 

3. The model does a good job and we want to use it

4. We saved the model

5. We want to use the model to target customers


## How to use the model?


- Integrate ("deploy") the model in a dashboard (e.g. [Streamlit]((https://streamlit.io/)))

- Use an API (e.g. [FastAPI](https://fastapi.tiangolo.com/)) to allow other software applications to use the model


## Streamlit dashboard 

![](images/streamlit.png)


## FastAPI

<!--

- Run the FastAPI app:

. . .

```bash
uvicorn fastapi_app:app --reload

```

-->

- FastAPI app with a single `/predict` endpoint 

- Accepts POST requests with JSON data containing age, city, income, membership days, and campaign engagement. 

- The app will return a JSON response with the prediction.

## Test API with data

- You can test the API using Python's requests library:

. . .

```{python}
# | eval: false
# | code-line-numbers: "|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20"

url = "http://127.0.0.1:8000/predict"
data = {
    "data": [
        {
            "age": 25,
            "city": "city_Berlin",
            "income": 25000,
            "membership_days": 4,
            "campaign_engagement": 1
        },
        {
            "age": 35,
            "city": "city_Stuttgart",
            "income": 120000,
            "membership_days": 250,
            "campaign_engagement": 8
        }
    ]
}


```


<!--
You can test the API using a tool like [Postman](https://www.postman.com/) or by using Python's requests library:

-->

## Get response


```{python}
# | eval: false
# | code-line-numbers: "|1|2|3|4|5|6|7|8|9|10|11|12"

response = requests.post(url, json=data)

if response.status_code == 200:
    results = response.json()['results']
    df = pd.DataFrame(results)
    df.to_csv('predictions.csv', index=False)
    print("Predictions saved to 'predictions.csv'")
else:
    print(f"Error: {response.status_code}")
    print(response.text)


```

## Output


```bash
age,city,income,membership_days,campaign_engagement,prediction
25,city_Berlin,25000,4,1,0.01
35,city_Stuttgart,120000,250,8,0.97
```

## Marketing campaign

- Next, we would filter all customers at a certain threshold

- What would be a good threshold?

- Only target those customers with the marketing campaign


# Questions? {background-image="images/marketing.png"}